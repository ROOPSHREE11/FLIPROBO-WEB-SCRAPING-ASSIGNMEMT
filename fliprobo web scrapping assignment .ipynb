{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16739057",
   "metadata": {},
   "source": [
    "# Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92267900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you knowÂ ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "headers = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])\n",
    "\n",
    "for header in headers:\n",
    "    print(header.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb147cf0",
   "metadata": {},
   "source": [
    "# Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2f70ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found on the page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\"\n",
    "                     \n",
    "table = soup.find(\"table\", class_=\"chart\")\n",
    "\n",
    "\n",
    "if table is not None:\n",
    "    \n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    movie_names = []\n",
    "    ratings = []\n",
    "    years = []\n",
    "\n",
    "    for row in rows[1:101]:\n",
    "        \n",
    "        columns = row.find_all(\"td\")\n",
    "        movie_name = columns[1].find(\"a\").text.strip()\n",
    "        rating = columns[2].strong.text.strip()\n",
    "        year = columns[1].span.text.strip(\"()\")\n",
    "\n",
    "        movie_names.append(movie_name)\n",
    "        ratings.append(rating)\n",
    "        years.append(year)\n",
    "\n",
    "    \n",
    "    data = {\n",
    "        \"Movie Name\": movie_names,\n",
    "        \"Rating\": ratings,\n",
    "        \"Year of Release\": years\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No data found on the page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd96a7",
   "metadata": {},
   "source": [
    "# Answer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26840735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No restaurants found on the page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.dineout.co.in/bangalore-restaurants\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "\n",
    "restaurants_container = soup.find(\"div\", class_=\"listingOuter\")\n",
    "if restaurants_container is not None:\n",
    "\n",
    "    restaurant_cards = restaurants_container.find_all(\"div\", class_=\"listing\")\n",
    "\n",
    "    restaurant_names = []\n",
    "    cuisines = []\n",
    "    locations = []\n",
    "    ratings = []\n",
    "    image_urls = []\n",
    "\n",
    "    for card in restaurant_cards:\n",
    "        \n",
    "        name = card.find(\"div\", class_=\"restntName\").text.strip()\n",
    "        restaurant_names.append(name)\n",
    "\n",
    "        \n",
    "        cuisine = card.find(\"div\", class_=\"double-line-ellipsis\").text.strip()\n",
    "        cuisines.append(cuisine)\n",
    "\n",
    "        \n",
    "        location = card.find(\"div\", class_=\"restntLoc\").text.strip()\n",
    "        locations.append(location)\n",
    "\n",
    "       \n",
    "        rating = card.find(\"div\", class_=\"rating-outer\").text.strip()\n",
    "        ratings.append(rating)\n",
    "\n",
    "        \n",
    "        image_url = card.find(\"img\")[\"src\"]\n",
    "        image_urls.append(image_url)\n",
    "\n",
    "   \n",
    "    data = {\n",
    "        \"Restaurant Name\": restaurant_names,\n",
    "        \"Cuisine\": cuisines,\n",
    "        \"Location\": locations,\n",
    "        \"Ratings\": ratings,\n",
    "        \"Image URL\": image_urls\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No restaurants found on the page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f7d96",
   "metadata": {},
   "source": [
    "# Answer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db08fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found on the page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "\n",
    "table = soup.find(\"table\", class_=\"tablepress tablepress-id-20\")\n",
    "\n",
    "\n",
    "if table is not None:\n",
    "  \n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    names = []\n",
    "    terms = []\n",
    "\n",
    "    for row in rows[1:]:\n",
    "       \n",
    "        columns = row.find_all(\"td\")\n",
    "        name = columns[0].text.strip()\n",
    "        term = columns[1].text.strip()\n",
    "\n",
    "        names.append(name)\n",
    "        terms.append(term)\n",
    "\n",
    "  \n",
    "    data = {\n",
    "        \"Name\": names,\n",
    "        \"Term of Office\": terms\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"No data found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f979e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
